{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IL_project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Xo0CaCx86994"
      },
      "source": [
        "**Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ry2xEpbl6999",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "outputId": "fb1acc2f-6ea4-4bf6-e30f-49827cad3f6c"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, ConcatDataset\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "from data_loader import iCIFAR100\n",
        "from model import incrementalNet\n",
        "from iCarl import iCaRLNet\n",
        "from LF_iCarl import LFiCaRLNet\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vHu3DUPe69-P"
      },
      "source": [
        "**Prepare Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tDsVeSPF69-Q",
        "colab": {}
      },
      "source": [
        "train_transform = transforms.Compose([transforms.RandomCrop(32, padding=4),\n",
        "                                      transforms.RandomHorizontalFlip(),\n",
        "                                      transforms.ToTensor(),       # Turn PIL Image to torch.Tensor\n",
        "                                      transforms.Normalize((0.507, 0.487, 0.441), (0.267, 0.256, 0.276)) \n",
        "])\n",
        "eval_transform = transforms.Compose([transforms.ToTensor(),       # Turn PIL Image to torch.Tensor\n",
        "                                      transforms.Normalize((0.507, 0.487, 0.441), (0.267, 0.256, 0.276)) \n",
        "])"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q-paXQC469-Z",
        "colab": {}
      },
      "source": [
        "random.seed(34)\n",
        "order = np.arange(0,100)\n",
        "random.shuffle(order)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jPAxRxND69-f"
      },
      "source": [
        "LEARNING WITHOUT FORGETTING/FINETUNING\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oYWBu_rm69-g",
        "colab": {}
      },
      "source": [
        "# BATCH_SIZE = 128\n",
        "# iNet = incrementalNet(10, 100, finetuning=True, verbose = False)\n",
        "# iNet.cuda()\n",
        "\n",
        "# conf_matrix_pred = []\n",
        "# conf_matrix_labels = []\n",
        "# for i in range(0,100,10):\n",
        "\n",
        "#   train_dataset = iCIFAR100(\"cifar-100\", classes=order[i:(i+10)],  train=True, download=True, transform=train_transform)\n",
        "#   test_dataset = iCIFAR100(\"cifar-100\", classes=order[0:(i+10)], train=False, transform=eval_transform)\n",
        "\n",
        "#   test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, \n",
        "#                                shuffle=False, num_workers=4, drop_last=False)\n",
        "#   train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, \n",
        "#                                 shuffle=False, num_workers=4, drop_last=False)\n",
        "\n",
        "#   iNet.update_representation(train_dataset, order)\n",
        "\n",
        "#   iNet.n_known += iNet.n_classes\n",
        "#   print (\"\\niCaRL classes: %d\" % iNet.n_known)\n",
        "\n",
        "#   total = 0.0\n",
        "#   correct = 0.0\n",
        "#   iNet.resnet.train(False)\n",
        "#   for images, labels in train_dataloader:\n",
        "#       images = images.to(device=\"cuda\")\n",
        "#       labels = labels.to(device=\"cuda\")\n",
        "#       preds = iNet.forward(images)\n",
        "#       _, preds = torch.max(preds.data, 1)\n",
        "#       #preds = torch.tensor([order[i] for i in preds]).cuda()\n",
        "#       total += labels.size(0)\n",
        "#       correct += (preds == labels.data).sum()\n",
        "#   accuracy = 100 * correct / total\n",
        "#   print('Train Accuracy: %.1f %%' % (accuracy))\n",
        "\n",
        "#   if iNet.finetuning:\n",
        "#     suf = 'finetuning.txt'\n",
        "#   else:\n",
        "#     suf = 'lwf.txt'\n",
        "\n",
        "#   with open(\"train_accuracy_\"+suf, \"a\") as f:\n",
        "#     f.write(str(accuracy.data)+\"\\n\")\n",
        "\n",
        "#   total = 0.0\n",
        "#   correct = 0.0\n",
        "#   for images, labels in test_dataloader:\n",
        "#       images = images.to(device=\"cuda\")\n",
        "#       labels = labels.to(device=\"cuda\")\n",
        "#       preds = iNet.forward(images)\n",
        "#       _, preds = torch.max(preds.data, 1)\n",
        "#       #preds = torch.tensor([order[i] for i in preds]).cuda()\n",
        "#       total += labels.size(0)\n",
        "#       correct += (preds == labels.data).sum()\n",
        "#       if iNet.n_known == 100:\n",
        "#         conf_matrix_pred += list(preds.data)\n",
        "#         conf_matrix_labels += list(labels.data)\n",
        "#   accuracy = 100 * correct / total\n",
        "#   print('Test Accuracy: %.1f %%\\n---------------' % (accuracy))\n",
        "#   with open(\"test_accuracy_\"+suf, \"a\") as f:\n",
        "#     f.write(str(accuracy.data)+\"\\n\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IWvUkaQt69-s"
      },
      "source": [
        "**ICARL**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CCeF0nmu69-t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "560a6207-67ff-4119-fd94-e4933a8837e6"
      },
      "source": [
        "K = 2000 # number of exemplars\n",
        "\"\"\"Possible choices as classifier: \n",
        "'standard' --> Nearest Mean\n",
        "'svm' -------> Linear SVM\n",
        "'knn' -------> K-nearest neighbours\n",
        "'trees' -----> Random forest  \n",
        "\"\"\"\n",
        "cl_name = 'standard'\n",
        "\"\"\"Possible choices as loss combination: \n",
        "'bce+bce' --> class: bce, dist: bce\n",
        "'ce+bce' ---> class: ce, dist: bce\n",
        "'l2+bce' ---> class: L2, dist: bce\n",
        "'bce+l2' ---> class: bce, dist: L2  \n",
        "\"\"\"\n",
        "loss_combination = 'bce+bce'\n",
        "\n",
        "\n",
        "icarl = iCaRLNet(10, 100, eval_transform, loss=loss_combination, classifier_name=cl_name, verbose=False)\n",
        "icarl.cuda()\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "conf_matrix_pred = []\n",
        "conf_matrix_labels = []\n",
        "for i in range(0,100,10):\n",
        "  \n",
        "  train_dataset = iCIFAR100(\"cifar-100\", classes=order[i:(i+10)],  train=True, download=True, transform=train_transform)\n",
        "  test_dataset = iCIFAR100(\"cifar-100\", classes=order[0:(i+10)], train=False, transform=eval_transform)\n",
        "\n",
        "  train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
        "  test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
        "\n",
        "  icarl.update_representation(train_dataset, order)\n",
        "\n",
        "  icarl.n_known += icarl.n_classes\n",
        "  m = int(K / icarl.n_known)\n",
        "\n",
        "  # Compute centroids before exemplars reduction\n",
        "  if cl_name == 'standard':\n",
        "    icarl.compute_means_and_features(train_dataset)\n",
        "\n",
        "  # Reduce exemplar sets for known classes\n",
        "  icarl.reduce_exemplar_sets(m)\n",
        "  \n",
        "  # Construct exemplar sets for new classes\n",
        "  for y in tqdm(order[i:(i+10)], desc=\"Generating exemplars\"):\n",
        "    images = train_dataset.get_image_class(y)\n",
        "    icarl.construct_exemplar_set(images, m)\n",
        "\n",
        "  # Compute features after exemplars construction\n",
        "  if cl_name != 'standard':\n",
        "    icarl.compute_means_and_features(train_dataset)\n",
        "\n",
        "  \n",
        "  print (\"\\niCaRL classes: %d\" % icarl.n_known)\n",
        "\n",
        "  total = 0.0\n",
        "  correct = 0.0\n",
        "  icarl.resnet.eval()\n",
        "  for images, labels in train_dataloader:\n",
        "      images = images.to(device=\"cuda\")\n",
        "      preds = icarl.classify(images)\n",
        "      total += labels.size(0)\n",
        "      correct += (preds.data.cpu() == labels).sum()\n",
        "  accuracy = 100 * correct / total\n",
        "  print('Train Accuracy: %.3f %%' % (accuracy))\n",
        "  with open(\"train_accuracy_iCaRL.txt\", \"a\") as f:\n",
        "    f.write(str(accuracy.data)+\"\\n\")\n",
        "\n",
        "\n",
        "  total = 0.0\n",
        "  correct = 0.0\n",
        "  icarl.resnet.eval()\n",
        "  for images, labels in test_dataloader:\n",
        "      images = images.to(device=\"cuda\")\n",
        "      preds = icarl.classify(images)\n",
        "      total += labels.size(0)\n",
        "      correct += (preds.data.cpu() == labels).sum()\n",
        "      if icarl.n_known == 100:\n",
        "        conf_matrix_pred += list(preds.data)\n",
        "        conf_matrix_labels += list(labels.data)\n",
        "  accuracy = 100 * correct / total\n",
        "  print('Test Accuracy: %.3f %%\\n---------------' % (accuracy))\n",
        "  with open(\"test_accuracy_iCaRL.txt\", \"a\") as f:\n",
        "    f.write(str(accuracy.data)+\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training:  71%|███████▏  | 50/70 [02:16<00:54,  2.74s/it]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-qmUlJnVR4V",
        "colab_type": "text"
      },
      "source": [
        "**MODIFIED ICARL**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUuz4LBFxEP3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# K = 2000 # number of exemplars\n",
        "\n",
        "\n",
        "# icarl = LFiCaRLNet(10, 100, eval_transform, verbose=False)\n",
        "# icarl.cuda()\n",
        "# BATCH_SIZE = 128\n",
        "\n",
        "# conf_matrix_pred = []\n",
        "# conf_matrix_labels = []\n",
        "# for i in range(0,100,10):\n",
        "  \n",
        "#   train_dataset = iCIFAR100(\"cifar-100\", classes=order[i:(i+10)],  train=True, download=True, transform=train_transform)\n",
        "#   test_dataset = iCIFAR100(\"cifar-100\", classes=order[0:(i+10)], train=False, transform=eval_transform)\n",
        "\n",
        "#   train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
        "#   test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
        "\n",
        "#   icarl.update_representation(train_dataset, order)\n",
        "\n",
        "#   icarl.n_known += icarl.n_classes\n",
        "#   m = int(K / icarl.n_known)\n",
        "\n",
        "#   # Compute centroids before exemplars reduction\n",
        "#   icarl.compute_means_and_features(train_dataset)\n",
        "\n",
        "#   # Reduce exemplar sets for known classes\n",
        "#   icarl.reduce_exemplar_sets(m)\n",
        "  \n",
        "#   # Construct exemplar sets for new classes\n",
        "#   for y in tqdm(order[i:(i+10)], desc=\"Generating exemplars\"):\n",
        "#     images = train_dataset.get_image_class(y)\n",
        "#     icarl.construct_exemplar_set(images, m)\n",
        "  \n",
        "#   print (\"\\niCaRL classes: %d\" % icarl.n_known)\n",
        "\n",
        "#   total = 0.0\n",
        "#   correct = 0.0\n",
        "#   icarl.resnet.eval()\n",
        "#   for images, labels in train_dataloader:\n",
        "#       images = images.to(device=\"cuda\")\n",
        "#       preds = icarl.classify(images)\n",
        "#       total += labels.size(0)\n",
        "#       correct += (preds.data.cpu() == labels).sum()\n",
        "#   accuracy = 100 * correct / total\n",
        "#   print('Train Accuracy: %.3f %%' % (accuracy))\n",
        "#   with open(\"train_accuracy_LF_iCaRL.txt\", \"a\") as f:\n",
        "#     f.write(str(accuracy.data)+\"\\n\")\n",
        "\n",
        "\n",
        "#   total = 0.0\n",
        "#   correct = 0.0\n",
        "#   icarl.resnet.eval()\n",
        "#   for images, labels in test_dataloader:\n",
        "#       images = images.to(device=\"cuda\")\n",
        "#       preds = icarl.classify(images)\n",
        "#       total += labels.size(0)\n",
        "#       correct += (preds.data.cpu() == labels).sum()\n",
        "#       if icarl.n_known == 100:\n",
        "#         conf_matrix_pred += list(preds.data)\n",
        "#         conf_matrix_labels += list(labels.data)\n",
        "#   accuracy = 100 * correct / total\n",
        "#   print('Test Accuracy: %.3f %%\\n---------------' % (accuracy))\n",
        "#   with open(\"test_accuracy_LF_iCaRL.txt\", \"a\") as f:\n",
        "#     f.write(str(accuracy.data)+\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ph_VjOtpGHAY",
        "colab": {}
      },
      "source": [
        "array = confusion_matrix([list(order).index(i.item()) for i in conf_matrix_labels], [list(order).index(i.item()) for i in conf_matrix_pred])\n",
        "df_cm = pd.DataFrame(array, range(100), range(100))\n",
        "plt.figure(figsize = (20,14))\n",
        "sn.heatmap(df_cm) "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}