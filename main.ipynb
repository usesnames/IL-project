{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IL_project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Xo0CaCx86994"
      },
      "source": [
        "**Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ry2xEpbl6999",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "outputId": "1aba1cbc-5f5d-4bd1-a1d8-c5374fa96086"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, ConcatDataset\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "from data_loader import iCIFAR100\n",
        "from model import incrementalNet\n",
        "from iCarl import iCaRLNet\n",
        "from LF_iCarl import LFiCaRLNet\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vHu3DUPe69-P"
      },
      "source": [
        "**Prepare Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tDsVeSPF69-Q",
        "colab": {}
      },
      "source": [
        "train_transform = transforms.Compose([transforms.RandomCrop(32, padding=4),\n",
        "                                      transforms.RandomHorizontalFlip(),\n",
        "                                      transforms.ToTensor(),       # Turn PIL Image to torch.Tensor\n",
        "                                      transforms.Normalize((0.507, 0.487, 0.441), (0.267, 0.256, 0.276)) \n",
        "])\n",
        "eval_transform = transforms.Compose([transforms.ToTensor(),       # Turn PIL Image to torch.Tensor\n",
        "                                      transforms.Normalize((0.507, 0.487, 0.441), (0.267, 0.256, 0.276)) \n",
        "])"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q-paXQC469-Z",
        "colab": {}
      },
      "source": [
        "random.seed(34)\n",
        "order = np.arange(0,100)\n",
        "random.shuffle(order)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jPAxRxND69-f"
      },
      "source": [
        "LEARNING WITHOUT FORGETTING/FINETUNING\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oYWBu_rm69-g",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "iNet = incrementalNet(10, 100, finetuning=True, verbose = False)\n",
        "iNet.cuda()\n",
        "\n",
        "conf_matrix_pred = []\n",
        "conf_matrix_labels = []\n",
        "for i in range(0,100,10):\n",
        "\n",
        "  train_dataset = iCIFAR100(\"cifar-100\", classes=order[i:(i+10)],  train=True, download=True, transform=train_transform)\n",
        "  test_dataset = iCIFAR100(\"cifar-100\", classes=order[0:(i+10)], train=False, transform=eval_transform)\n",
        "\n",
        "  test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, \n",
        "                               shuffle=False, num_workers=4, drop_last=False)\n",
        "  train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, \n",
        "                                shuffle=False, num_workers=4, drop_last=False)\n",
        "\n",
        "  iNet.update_representation(train_dataset, order)\n",
        "\n",
        "  iNet.n_known += iNet.n_classes\n",
        "  print (\"\\niCaRL classes: %d\" % iNet.n_known)\n",
        "\n",
        "  total = 0.0\n",
        "  correct = 0.0\n",
        "  iNet.resnet.train(False)\n",
        "  for images, labels in train_dataloader:\n",
        "      images = images.to(device=\"cuda\")\n",
        "      labels = labels.to(device=\"cuda\")\n",
        "      preds = iNet.forward(images)\n",
        "      _, preds = torch.max(preds.data, 1)\n",
        "      #preds = torch.tensor([order[i] for i in preds]).cuda()\n",
        "      total += labels.size(0)\n",
        "      correct += (preds == labels.data).sum()\n",
        "  accuracy = 100 * correct / total\n",
        "  print('Train Accuracy: %.1f %%' % (accuracy))\n",
        "\n",
        "  if iNet.finetuning:\n",
        "    suf = 'finetuning.txt'\n",
        "  else:\n",
        "    suf = 'lwf.txt'\n",
        "\n",
        "  with open(\"train_accuracy_\"+suf, \"a\") as f:\n",
        "    f.write(str(accuracy.data)+\"\\n\")\n",
        "\n",
        "  total = 0.0\n",
        "  correct = 0.0\n",
        "  for images, labels in test_dataloader:\n",
        "      images = images.to(device=\"cuda\")\n",
        "      labels = labels.to(device=\"cuda\")\n",
        "      preds = iNet.forward(images)\n",
        "      _, preds = torch.max(preds.data, 1)\n",
        "      #preds = torch.tensor([order[i] for i in preds]).cuda()\n",
        "      total += labels.size(0)\n",
        "      correct += (preds == labels.data).sum()\n",
        "      if iNet.n_known == 100:\n",
        "        conf_matrix_pred += list(preds.data)\n",
        "        conf_matrix_labels += list(labels.data)\n",
        "  accuracy = 100 * correct / total\n",
        "  print('Test Accuracy: %.1f %%\\n---------------' % (accuracy))\n",
        "  with open(\"test_accuracy_\"+suf, \"a\") as f:\n",
        "    f.write(str(accuracy.data)+\"\\n\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5bAbjYqbpKn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "array = confusion_matrix([list(order).index(i.item()) for i in conf_matrix_labels], [list(order).index(i.item()) for i in conf_matrix_pred])\n",
        "df_cm = pd.DataFrame(array, range(100), range(100))\n",
        "plt.figure(figsize = (20,14))\n",
        "sn.heatmap(df_cm) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IWvUkaQt69-s"
      },
      "source": [
        "**ICARL**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CCeF0nmu69-t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "df9293ab-04b5-4d08-9016-bc34718d6203"
      },
      "source": [
        "K = 2000 # number of exemplars\n",
        "\n",
        "\"\"\"Possible choices as classifier: \n",
        "'standard' --> Nearest Mean\n",
        "'svm' -------> Linear SVM\n",
        "'knn' -------> K-nearest neighbours\n",
        "'trees' -----> Random forest  \n",
        "\"\"\"\n",
        "cl_name = 'standard'\n",
        "\n",
        "\"\"\"Possible choices as loss combination: \n",
        "'bce+bce' --> class: bce, dist: bce\n",
        "'ce+bce' ---> class: ce, dist: bce\n",
        "'l2+bce' ---> class: L2, dist: bce\n",
        "'bce+l2' ---> class: bce, dist: L2  \n",
        "\"\"\"\n",
        "loss_combination = 'bce+bce'\n",
        "\n",
        "\n",
        "icarl = iCaRLNet(10, 100, eval_transform, loss=loss_combination, classifier_name=cl_name, verbose=False)\n",
        "icarl.cuda()\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "conf_matrix_pred = []\n",
        "conf_matrix_labels = []\n",
        "for i in range(0,100,10):\n",
        "  \n",
        "  train_dataset = iCIFAR100(\"cifar-100\", classes=order[i:(i+10)],  train=True, download=True, transform=train_transform)\n",
        "  test_dataset = iCIFAR100(\"cifar-100\", classes=order[0:(i+10)], train=False, transform=eval_transform)\n",
        "\n",
        "  train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
        "  test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
        "\n",
        "  icarl.update_representation(train_dataset, order)\n",
        "\n",
        "  icarl.n_known += icarl.n_classes\n",
        "  m = int(K / icarl.n_known)\n",
        "\n",
        "  # Compute centroids before exemplars reduction\n",
        "  if cl_name == 'standard':\n",
        "    icarl.compute_means_and_features(train_dataset)\n",
        "\n",
        "  # Reduce exemplar sets for known classes\n",
        "  icarl.reduce_exemplar_sets(m)\n",
        "  \n",
        "  # Construct exemplar sets for new classes\n",
        "  for y in tqdm(order[i:(i+10)], desc=\"Generating exemplars\"):\n",
        "    images = train_dataset.get_image_class(y)\n",
        "    icarl.construct_exemplar_set(images, m)\n",
        "\n",
        "  # Compute features after exemplars construction\n",
        "  if cl_name != 'standard':\n",
        "    icarl.compute_means_and_features(train_dataset)\n",
        "\n",
        "  \n",
        "  print (\"\\niCaRL classes: %d\" % icarl.n_known)\n",
        "\n",
        "  total = 0.0\n",
        "  correct = 0.0\n",
        "  icarl.resnet.eval()\n",
        "  for images, labels in train_dataloader:\n",
        "      images = images.to(device=\"cuda\")\n",
        "      preds = icarl.classify(images)\n",
        "      total += labels.size(0)\n",
        "      correct += (preds.data.cpu() == labels).sum()\n",
        "  accuracy = 100 * correct / total\n",
        "  print('Train Accuracy: %.3f %%' % (accuracy))\n",
        "  with open(\"train_accuracy_iCaRL.txt\", \"a\") as f:\n",
        "    f.write(str(accuracy.data)+\"\\n\")\n",
        "\n",
        "\n",
        "  total = 0.0\n",
        "  correct = 0.0\n",
        "  icarl.resnet.eval()\n",
        "  for images, labels in test_dataloader:\n",
        "      images = images.to(device=\"cuda\")\n",
        "      preds = icarl.classify(images)\n",
        "      total += labels.size(0)\n",
        "      correct += (preds.data.cpu() == labels).sum()\n",
        "      if icarl.n_known == 100:\n",
        "        conf_matrix_pred += list(preds.data)\n",
        "        conf_matrix_labels += list(labels.data)\n",
        "  accuracy = 100 * correct / total\n",
        "  print('Test Accuracy: %.3f %%\\n---------------' % (accuracy))\n",
        "  with open(\"test_accuracy_iCaRL.txt\", \"a\") as f:\n",
        "    f.write(str(accuracy.data)+\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 70/70 [03:10<00:00,  2.73s/it]\n",
            "Computing mean of classes: 100%|██████████| 10/10 [00:20<00:00,  2.08s/it]\n",
            "Generating exemplars: 100%|██████████| 10/10 [00:25<00:00,  2.58s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "iCaRL classes: 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Accuracy: 97.820 %\n",
            "Test Accuracy: 86.400 %\n",
            "---------------\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rTraining:   0%|          | 0/70 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrPX7Cc_bmTg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "array = confusion_matrix([list(order).index(i.item()) for i in conf_matrix_labels], [list(order).index(i.item()) for i in conf_matrix_pred])\n",
        "df_cm = pd.DataFrame(array, range(100), range(100))\n",
        "plt.figure(figsize = (20,14))\n",
        "sn.heatmap(df_cm) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-qmUlJnVR4V",
        "colab_type": "text"
      },
      "source": [
        "**MODIFIED ICARL**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUuz4LBFxEP3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "K = 2000 # number of exemplars\n",
        "\n",
        "\n",
        "icarl = LFiCaRLNet(10, 100, eval_transform, verbose=False)\n",
        "icarl.cuda()\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "conf_matrix_pred = []\n",
        "conf_matrix_labels = []\n",
        "for i in range(0,100,10):\n",
        "  \n",
        "  train_dataset = iCIFAR100(\"cifar-100\", classes=order[i:(i+10)],  train=True, download=True, transform=train_transform)\n",
        "  test_dataset = iCIFAR100(\"cifar-100\", classes=order[0:(i+10)], train=False, transform=eval_transform)\n",
        "\n",
        "  train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
        "  test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
        "\n",
        "  icarl.update_representation(train_dataset, order)\n",
        "\n",
        "  icarl.n_known += icarl.n_classes\n",
        "  m = int(K / icarl.n_known)\n",
        "\n",
        "  # Compute centroids before exemplars reduction\n",
        "  icarl.compute_means_and_features(train_dataset)\n",
        "\n",
        "  # Reduce exemplar sets for known classes\n",
        "  icarl.reduce_exemplar_sets(m)\n",
        "  \n",
        "  # Construct exemplar sets for new classes\n",
        "  for y in tqdm(order[i:(i+10)], desc=\"Generating exemplars\"):\n",
        "    images = train_dataset.get_image_class(y)\n",
        "    icarl.construct_exemplar_set(images, m)\n",
        "  \n",
        "  print (\"\\niCaRL classes: %d\" % icarl.n_known)\n",
        "\n",
        "  total = 0.0\n",
        "  correct = 0.0\n",
        "  icarl.resnet.eval()\n",
        "  for images, labels in train_dataloader:\n",
        "      images = images.to(device=\"cuda\")\n",
        "      preds = icarl.classify(images)\n",
        "      total += labels.size(0)\n",
        "      correct += (preds.data.cpu() == labels).sum()\n",
        "  accuracy = 100 * correct / total\n",
        "  print('Train Accuracy: %.3f %%' % (accuracy))\n",
        "  with open(\"train_accuracy_LF_iCaRL.txt\", \"a\") as f:\n",
        "    f.write(str(accuracy.data)+\"\\n\")\n",
        "\n",
        "\n",
        "  total = 0.0\n",
        "  correct = 0.0\n",
        "  icarl.resnet.eval()\n",
        "  for images, labels in test_dataloader:\n",
        "      images = images.to(device=\"cuda\")\n",
        "      preds = icarl.classify(images)\n",
        "      total += labels.size(0)\n",
        "      correct += (preds.data.cpu() == labels).sum()\n",
        "      if icarl.n_known == 100:\n",
        "        conf_matrix_pred += list(preds.data)\n",
        "        conf_matrix_labels += list(labels.data)\n",
        "  accuracy = 100 * correct / total\n",
        "  print('Test Accuracy: %.3f %%\\n---------------' % (accuracy))\n",
        "  with open(\"test_accuracy_LF_iCaRL.txt\", \"a\") as f:\n",
        "    f.write(str(accuracy.data)+\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ph_VjOtpGHAY",
        "colab": {}
      },
      "source": [
        "array = confusion_matrix([list(order).index(i.item()) for i in conf_matrix_labels], [list(order).index(i.item()) for i in conf_matrix_pred])\n",
        "df_cm = pd.DataFrame(array, range(100), range(100))\n",
        "plt.figure(figsize = (20,14))\n",
        "sn.heatmap(df_cm) "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}